{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://python.langchain.com/v0.1/docs/use_cases/tool_use/prompting/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain import hub\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langgraph.graph import END, StateGraph\n",
    "from typing import Dict, TypedDict\n",
    "from langchain.prompts import PromptTemplate\n",
    "import pprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    api_key=\"ollama\",\n",
    "    model=\"elvee/hermes-2-pro-llama-3:8b-Q5_K_M\",\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first_int * second_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply.invoke({\"first_int\": 4, \"second_int\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.render import render_text_description\n",
    "\n",
    "rendered_tools = render_text_description([multiply])\n",
    "rendered_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example: \n",
    "{'name': 'multiply', 'arguments': {'arg1': value_1, 'arg2': value_2}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool: \n",
    "\n",
    "\"\"\" + rendered_tools + \"\"\"\n",
    "\n",
    "Given the user input, return the name and input of the tool to use. \n",
    "Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
    "For example: \n",
    "{{'name': 'multiply', 'arguments': {{'arg1': value_1, 'arg2': value_2}}}}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(system_prompt)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser()\n",
    "chain.invoke({\"input\": \"what's thirteen times 4\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = prompt | llm | JsonOutputParser() | itemgetter(\"arguments\") | multiply\n",
    "chain.invoke({\"input\": \"what's thirteen times 4\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agentic AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
